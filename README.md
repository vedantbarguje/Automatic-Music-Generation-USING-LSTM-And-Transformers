# Automatic-Music-Generation-USING-LSTM-And-Transformers
The use of artificial intelligence has provided new opportunities for natural music creation through automatic music generation the subsequent creation of complex composing music therefore requires a lesser engagement of the user. This work describes a new framework for creating music based on deep learning methods, including LSTM and Transformer models. The system extends Sequence Analysis to MIDI sequences, utilizes LSTM models to learn temporal dependencies and generates new music using Encoder-Decoder Transformers in the sequence-to-sequence framework to enhance the output into contextually structured musical developments. The presented approach also has additional advantages because it completely eliminates particular domainâ€™s architecture of the models, and relies on more general sequence-to-sequence models, which makes the pipeline less complicated, and thus more scalable. The end product is a producing of Midi sequences which with the aid of synthesizers, are transformed into audio that appears to be original and of superior quality. This work shows the possibility of synthesizing LSTM and Transformer models in music generation and solves such issues as data heterogeneity, low-performance computations, and easy understanding of generated melody. The presented framework opens the path toward improvements in music information retrieval approach and AI music generation.
